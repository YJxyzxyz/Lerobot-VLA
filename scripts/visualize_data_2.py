"""
Replay Language-Conditioned Demonstration

Features:
1. Load dataset with language instructions
2. Replay collected demonstration data in simulation environment
3. Overlay dataset images for comparison and verification
4. (Optional) Upload dataset to Hugging Face Hub
"""

import numpy as np
import torch

from lerobot.common.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata
from lerobot.common.datasets.utils import write_json, serialize_dict
from mujoco_env.y_env2 import SimpleEnv2

# ========================
# Configuration Parameters
# ========================
ROOT = "./demo_data_language"
# ROOT = './omy_pnp_language'  # If using provided example data

REPO_NAME = 'omy_pnp_language'
XML_PATH = './asset/example_scene_y2.xml'
EPISODE_INDEX = 0


class EpisodeSampler(torch.utils.data.Sampler):
    """
    Sampler for a single episode
    """

    def __init__(self, dataset: LeRobotDataset, episode_index: int):
        from_idx = dataset.episode_data_index["from"][episode_index].item()
        to_idx = dataset.episode_data_index["to"][episode_index].item()
        self.frame_ids = range(from_idx, to_idx)

    def __iter__(self):
        return iter(self.frame_ids)

    def __len__(self) -> int:
        return len(self.frame_ids)


def main():
    # Load dataset
    dataset = LeRobotDataset(REPO_NAME, root=ROOT)

    # Create episode sampler and dataloader
    episode_sampler = EpisodeSampler(dataset, EPISODE_INDEX)
    dataloader = torch.utils.data.DataLoader(
        dataset,
        num_workers=1,
        batch_size=1,
        sampler=episode_sampler,
    )

    # Load environment
    PnPEnv = SimpleEnv2(XML_PATH, action_type='joint_angle')

    # Replay loop
    step = 0
    iter_dataloader = iter(dataloader)
    PnPEnv.reset()

    while PnPEnv.env.is_viewer_alive():
        PnPEnv.step_env()
        if PnPEnv.env.loop_every(HZ=20):
            # Get data from dataset
            data = next(iter_dataloader)

            if step == 0:
                # Set language instruction and initial object positions
                instruction = data['task'][0]
                PnPEnv.set_instruction(instruction)
                PnPEnv.set_obj_pose(
                    data['obj_init'][0, :3],
                    data['obj_init'][0, 3:6],
                    data['obj_init'][0, 6:9]
                )

            # Execute action
            action = data['action'].numpy()
            obs = PnPEnv.step(action[0])

            # Visualize images from dataset
            PnPEnv.rgb_agent = data['observation.image'][0].numpy() * 255
            PnPEnv.rgb_ego = data['observation.wrist_image'][0].numpy() * 255
            PnPEnv.rgb_agent = PnPEnv.rgb_agent.astype(np.uint8)
            PnPEnv.rgb_ego = PnPEnv.rgb_ego.astype(np.uint8)
            # (3, 256, 256) -> (256, 256, 3)
            PnPEnv.rgb_agent = np.transpose(PnPEnv.rgb_agent, (1, 2, 0))
            PnPEnv.rgb_ego = np.transpose(PnPEnv.rgb_ego, (1, 2, 0))
            PnPEnv.rgb_side = np.zeros((480, 640, 3), dtype=np.uint8)

            PnPEnv.render()
            step += 1

            # Loop replay
            if step == len(episode_sampler):
                iter_dataloader = iter(dataloader)
                PnPEnv.reset()
                step = 0

    # Close environment
    PnPEnv.env.close_viewer()


def upload_to_hub():
    """Upload dataset to Hugging Face Hub"""
    dataset = LeRobotDataset(REPO_NAME, root=ROOT)
    dataset.push_to_hub(upload_large_folder=True)


if __name__ == "__main__":
    main()
    # upload_to_hub()  # Uncomment to upload to Hugging Face